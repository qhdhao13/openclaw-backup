#!/usr/bin/env python3
"""
è‡ªå­¦ä¹ å¼•æ“
æ¯æ—¥è‡ªåŠ¨æ€»ç»“å¯¹è¯ï¼Œæå–åå¥½ã€ä¹ æƒ¯ã€ç›®æ ‡ï¼Œæ„å»ºä¸“å±ä¸ªäººæ¨¡å‹
"""

import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from collections import Counter, defaultdict

MEMORY_DB_DIR = Path.home() / ".openclaw" / "workspace" / "memory-db"
LEARNING_FILE = MEMORY_DB_DIR / "learning_model.json"
DAILY_SUMMARY_FILE = MEMORY_DB_DIR / "daily_summaries.json"

class SelfLearningEngine:
    """è‡ªå­¦ä¹ å¼•æ“ - æŒç»­è¿›åŒ–"""
    
    def __init__(self):
        self.db_dir = MEMORY_DB_DIR
        self.db_dir.mkdir(parents=True, exist_ok=True)
        self.learning_model = self._load_model()
        
    def _load_model(self):
        """åŠ è½½å­¦ä¹ æ¨¡å‹"""
        if LEARNING_FILE.exists():
            with open(LEARNING_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            "created_at": datetime.now().isoformat(),
            "version": "2.0.0",
            "user_profile": {
                "preferences": {},
                "habits": {},
                "communication_style": {},
                "common_tasks": [],
                "goals": [],
                "avoid_patterns": []
            },
            "learning_stats": {
                "total_days": 0,
                "total_conversations": 0,
                "insights_extracted": 0
            }
        }
    
    def _save_model(self):
        """ä¿å­˜å­¦ä¹ æ¨¡å‹"""
        with open(LEARNING_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.learning_model, f, ensure_ascii=False, indent=2)
    
    def daily_summary(self, conversations):
        """æ¯æ—¥å¯¹è¯æ€»ç»“"""
        if not conversations:
            return None
        
        summary = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "total_interactions": len(conversations),
            "topics": self._extract_topics(conversations),
            "preferences": self._extract_preferences(conversations),
            "habits": self._extract_habits(conversations),
            "insights": self._generate_insights(conversations),
            "mood_trend": self._analyze_mood(conversations)
        }
        
        # æ›´æ–°å­¦ä¹ æ¨¡å‹
        self._update_learning_model(summary)
        
        # ä¿å­˜æ¯æ—¥æ€»ç»“
        self._save_daily_summary(summary)
        
        return summary
    
    def _extract_topics(self, conversations):
        """æå–è¯é¢˜"""
        all_text = " ".join([c["input"] for c in conversations])
        # ç®€å•çš„å…³é”®è¯æå–
        keywords = []
        important_words = [
            "ä»£ç ", "é¡¹ç›®", "é‚®ä»¶", "æ—¥ç¨‹", "æé†’", "å®šæ—¶", "é…ç½®",
            "openclaw", "é¾™è™¾", "è´¾ç»´æ–¯", "æŠ€èƒ½", "è®°å¿†", "å¤‡ä»½"
        ]
        for word in important_words:
            if word in all_text:
                keywords.append(word)
        return list(set(keywords))[:10]
    
    def _extract_preferences(self, conversations):
        """æå–åå¥½"""
        prefs = {}
        
        # åˆ†æç”¨æˆ·å–œæ¬¢çš„å“åº”æ–¹å¼
        for conv in conversations:
            input_text = conv["input"].lower()
            
            # æ£€æµ‹ç®€æ´åå¥½
            if any(word in input_text for word in ["ç®€æ´", "ç®€çŸ­", "ä¸è¦åºŸè¯"]):
                prefs["response_length"] = "brief"
            
            # æ£€æµ‹è¯¦ç»†åå¥½
            if any(word in input_text for word in ["è¯¦ç»†", "å®Œæ•´", "å±•å¼€"]):
                prefs["response_length"] = "detailed"
            
            # æ£€æµ‹ä¸»åŠ¨åå¥½
            if any(word in input_text for word in ["ä¸»åŠ¨", "æé†’", "æå‰"]):
                prefs["proactive"] = True
        
        return prefs
    
    def _extract_habits(self, conversations):
        """æå–ä¹ æƒ¯"""
        habits = defaultdict(lambda: {"count": 0, "last_time": None})
        
        for conv in conversations:
            input_text = conv["input"].lower()
            timestamp = conv.get("timestamp", datetime.now().isoformat())
            
            # æ£€æµ‹é«˜é¢‘æ“ä½œ
            if "æ£€æŸ¥" in input_text:
                habits["checking"]["count"] += 1
                habits["checking"]["last_time"] = timestamp
            
            if "å‘é€" in input_text or "é‚®ä»¶" in input_text:
                habits["email"]["count"] += 1
                habits["email"]["last_time"] = timestamp
            
            if "å®šæ—¶" in input_text or "cron" in input_text:
                habits["scheduling"]["count"] += 1
                habits["scheduling"]["last_time"] = timestamp
        
        return dict(habits)
    
    def _generate_insights(self, conversations):
        """ç”Ÿæˆæ´å¯Ÿ"""
        insights = []
        
        # åˆ†æå¸¸è§é—®é¢˜
        questions = [c["input"] for c in conversations if "?" in c["input"] or "ï¼Ÿ" in c["input"]]
        if len(questions) > 5:
            insights.append(f"ç”¨æˆ·ä»Šæ—¥æé—® {len(questions)} æ¬¡ï¼Œè¡¨ç°å‡ºè¾ƒå¼ºçš„æ¢ç´¢å’Œå­¦ä¹ æ„æ„¿")
        
        # åˆ†æä»»åŠ¡å®Œæˆåº¦
        tasks = [c for c in conversations if any(word in c["input"] for word in ["å®Œæˆ", "åšå¥½", "æå®š"])]
        if len(tasks) > 3:
            insights.append(f"ä»Šæ—¥å®Œæˆäº† {len(tasks)} é¡¹ä»»åŠ¡ï¼Œæ‰§è¡Œæ•ˆç‡é«˜")
        
        return insights
    
    def _analyze_mood(self, conversations):
        """åˆ†ææƒ…ç»ªè¶‹åŠ¿"""
        # ç®€å•çš„æƒ…ç»ªå…³é”®è¯æ£€æµ‹
        positive_words = ["å¥½", "æ£’", "ä¼˜ç§€", "å®Œç¾", "è°¢è°¢", "æ„Ÿè°¢"]
        negative_words = ["é”™", "é—®é¢˜", "æ…¢", "å¡", "å¤±è´¥", "é”™è¯¯"]
        
        positive_count = sum(1 for c in conversations if any(w in c["input"] for w in positive_words))
        negative_count = sum(1 for c in conversations if any(w in c["input"] for w in negative_words))
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "concerned"
        return "neutral"
    
    def _update_learning_model(self, summary):
        """æ›´æ–°å­¦ä¹ æ¨¡å‹"""
        profile = self.learning_model["user_profile"]
        
        # æ›´æ–°åå¥½
        for key, value in summary.get("preferences", {}).items():
            profile["preferences"][key] = value
        
        # æ›´æ–°ä¹ æƒ¯
        for key, value in summary.get("habits", {}).items():
            profile["habits"][key] = value
        
        # æ›´æ–°ç»Ÿè®¡
        self.learning_model["learning_stats"]["total_days"] += 1
        self.learning_model["learning_stats"]["total_conversations"] += summary["total_interactions"]
        self.learning_model["learning_stats"]["insights_extracted"] += len(summary.get("insights", []))
        
        self._save_model()
    
    def _save_daily_summary(self, summary):
        """ä¿å­˜æ¯æ—¥æ€»ç»“"""
        summaries = []
        if DAILY_SUMMARY_FILE.exists():
            with open(DAILY_SUMMARY_FILE, 'r', encoding='utf-8') as f:
                summaries = json.load(f)
        
        summaries.append(summary)
        
        with open(DAILY_SUMMARY_FILE, 'w', encoding='utf-8') as f:
            json.dump(summaries, f, ensure_ascii=False, indent=2)
    
    def get_user_model(self):
        """è·å–ç”¨æˆ·ä¸“å±æ¨¡å‹"""
        return self.learning_model["user_profile"]
    
    def get_learning_stats(self):
        """è·å–å­¦ä¹ ç»Ÿè®¡"""
        return self.learning_model["learning_stats"]

# å…¨å±€å®ä¾‹
learning_engine = SelfLearningEngine()

if __name__ == "__main__":
    print("ğŸ§¬ è‡ªå­¦ä¹ å¼•æ“")
    print("=" * 40)
    stats = learning_engine.get_learning_stats()
    print(f"å­¦ä¹ å¤©æ•°: {stats['total_days']}")
    print(f"å¯¹è¯æ€»æ•°: {stats['total_conversations']}")
    print(f"æ´å¯Ÿæå–: {stats['insights_extracted']}")
    print("=" * 40)
    print("\nğŸ“Š ç”¨æˆ·ä¸“å±æ¨¡å‹æ„å»ºä¸­...")
    print("ğŸ’¡ æ¯æ—¥23:00è‡ªåŠ¨æ€»ç»“ï¼ŒæŒç»­ä¼˜åŒ–")
